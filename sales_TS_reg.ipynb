{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45689a",
   "metadata": {
    "id": "bf45689a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pmdarima\n",
    "from IPython.display import clear_output\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heJUyCbby_wk",
   "metadata": {
    "id": "heJUyCbby_wk"
   },
   "outputs": [],
   "source": [
    "new_train=pd.read_csv(\"~/Downloads/store-sales-time-series-forecasting/new_train.csv\",parse_dates=True)\n",
    "\n",
    "new_train[\"date\"]=pd.to_datetime(new_train[\"date\"])\n",
    "\n",
    "stores=pd.read_csv(\"~/Downloads/store-sales-time-series-forecasting/stores.csv\")\n",
    "\n",
    "new_holiday=pd.read_csv(\"/home/avirup/Downloads/store-sales-time-series-forecasting/new_holiday.csv\",parse_dates=True)\n",
    "\n",
    "new_holiday[\"date\"]=pd.to_datetime(new_holiday[\"date\"])\n",
    "\n",
    "new_oil=pd.read_csv(\"~/Downloads/store-sales-time-series-forecasting/new_oil.csv\")\n",
    "\n",
    "new_oil[\"date\"]=pd.to_datetime(new_oil[\"date\"])\n",
    "\n",
    "#trans_csv=pd.read_csv(\"/home/avirup/Downloads/store-sales-time-series-forecasting/transactions.csv\")\n",
    "\n",
    "#trans_csv[\"date\"]=pd.to_datetime(trans_csv[\"date\"])\n",
    "\n",
    "#test_csv=pd.read_csv(\"/home/avirup/Downloads/store-sales-time-series-forecasting/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1503cf",
   "metadata": {
    "id": "ec1503cf"
   },
   "source": [
    "# OIL PRICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04151329",
   "metadata": {
    "id": "04151329"
   },
   "outputs": [],
   "source": [
    "new_oil.set_index(new_oil[\"date\"].values,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e478697",
   "metadata": {
    "id": "1e478697"
   },
   "outputs": [],
   "source": [
    "new_oil.index.freq=\"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8bd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_oil.drop(columns=\"date\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae1c4d",
   "metadata": {},
   "source": [
    "# HOLIDAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b326751",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_holiday.set_index(new_holiday[\"date\"].values,inplace=True)\n",
    "\n",
    "pd.DataFrame.drop(new_holiday,columns=\"date\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ creating the vectorised form of categorical variables #####################\n",
    "\n",
    "def feature_matrix_construct(features,columns_index,df,drop=False):\n",
    "    \n",
    "    temp=[]\n",
    "    for i in range(len(features)):\n",
    "        print(str(i)+\"...done\")\n",
    "        temp_feature_matrix=np.zeros((len(df),len(features[i])))\n",
    "        for j in range(temp_feature_matrix.shape[0]):\n",
    "                for k in range(len(features[i])):\n",
    "                    if df.iloc[j,columns_index[i]]==features[i][k]:\n",
    "                        temp_feature_matrix[j,k]=1\n",
    "       # print(np.delete(temp_feature_matrix,-1,1))\n",
    "        if drop==False:\n",
    "            temp.append(temp_feature_matrix)\n",
    "        else:\n",
    "            temp.append(np.delete(temp_feature_matrix,-1,1))\n",
    "        #print(temp)\n",
    "    feature_matrix=np.concatenate(tuple(temp),axis=1)\n",
    "    return(feature_matrix)\n",
    "\n",
    "Y=feature_matrix_construct(features=[np.delete(new_holiday[\"type\"].unique(),4),\\\n",
    "                                    np.delete(new_holiday[\"locale_name\"].unique(),14),\\\n",
    "                                        np.delete(new_holiday[\"transferred\"].unique(),0)],\\\n",
    "                                           columns_index=[0,1,2],df=new_holiday,drop=True)\n",
    "\n",
    "\n",
    "Z=pd.DataFrame(Y,index=new_holiday.index,columns=[str(i) for i in range(Y.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293106d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRAIN TEST SPLIT\n",
    "split_length=15\n",
    "auto_reg_order=3\n",
    "oil_lag_order=4\n",
    "holiday_lag_order=2\n",
    "##################\n",
    "\n",
    "############## creating lagged columns of holiday ##############################\n",
    "\n",
    "holiday_exog=Z.copy()\n",
    "iterate=holiday_exog.columns\n",
    "for i in range(1,holiday_lag_order+1):\n",
    "    for x in iterate:\n",
    "        holiday_exog[x+\" lag\" +str(i)]=holiday_exog[x].shift(i)\n",
    "\n",
    "holiday_exog.dropna(inplace=True)\n",
    "\n",
    "\n",
    "############## creating lagged columns of oil ####################################\n",
    "\n",
    "oil_exog=new_oil.copy()\n",
    "for i in range(1,oil_lag_order+1):\n",
    "    oil_exog[\"lag\"+str(i)]=oil_exog[\"price\"].shift(i)\n",
    "oil_exog=oil_exog.dropna()\n",
    "\n",
    "oil_exog.drop(columns=\"date\",inplace=True)\n",
    "\n",
    "\n",
    "############## array for appending results ####################################\n",
    "error_array=[]\n",
    "\n",
    "\n",
    "#################### looping over each store ##################################\n",
    "#################### regression will be done ##################################\n",
    "################### for each store separately #################################\n",
    "for k in new_train_csv[\"store_nbr\"].unique():\n",
    "    \n",
    "    ########### extracting the data for store no. k ##########################\n",
    "    Y=new_train_csv[new_train_csv[\"store_nbr\"]==k].copy()\n",
    "    Y.set_index(Y[\"date\"].values,inplace=True)\n",
    "    \n",
    "\n",
    "    ########### merging holiday and oil exogenous variables ###################\n",
    "    df_exog=pd.merge(holiday_exog,oil_exog,how=\"inner\",left_index=True,right_index=True)\n",
    "    \n",
    "    \n",
    "    idx=pd.date_range(df_exog.index[0],pd.to_datetime(\"2017-07-31\"),freq=\"D\")\n",
    "    \n",
    "    ########### creating dataframes for sales and promotions #################\n",
    "    df_sales=pd.DataFrame(columns=new_train_csv[\"family\"].unique(),index=idx)\n",
    "    df_promo=pd.DataFrame(columns=new_train_csv[\"family\"].unique(),index=idx)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    for x in df_sales.index:\n",
    "        df_sales.loc[x,:]=np.log(Y.loc[x][\"sales\"].values+1)\n",
    "        df_promo.loc[x,:]=np.log(Y.loc[x][\"onpromotion\"].values+1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ########### merging exogenous variables with promotion #################\n",
    "            \n",
    "\n",
    "    df_ind=pd.merge(df_promo,df_exog,how=\"inner\",left_index=True,right_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    ########### adding lagged sales to exogenous variables for final independent variables ################\n",
    "    \n",
    "    iterate=df_sales.columns\n",
    "    for i in range(0,auto_reg_order):\n",
    "        for x in iterate:\n",
    "            df_ind[x+\" lag\" +str(i+1)]=df_sales[x].shift(i+1)\n",
    "            \n",
    "    df_ind.dropna(inplace=True)\n",
    "            \n",
    "    ########## creating an object of xgb regressor ############\n",
    "\n",
    "    reg_model=xgb.XGBRegressor()\n",
    "\n",
    "    ########## fitting/ training the regressor ###################\n",
    "\n",
    "    reg_model.fit(df_ind.values.astype(np.float32)[:,:],df_sales.values.astype(np.float32)[auto_reg_order:,:])\n",
    "    \n",
    "    ########## predicted output over the train set ###############\n",
    "\n",
    "    pred_train=pd.DataFrame(reg_model.predict(df_ind.values.astype(np.float32)[:,:]),columns=df_sales.columns)\n",
    "\n",
    "\n",
    "    \n",
    "    ########### creating the test set for a 15 day split from 2017-08-1 to 2017-08-15 ###################\n",
    "    df_promo_test=pd.DataFrame(columns=new_train_csv[\"family\"].unique(),index=Y[\"date\"].unique()[-split_length:])\n",
    "    df_sales_test=pd.DataFrame(columns=new_train_csv[\"family\"].unique(),index=Y[\"date\"].unique()[-split_length:])\n",
    "\n",
    "\n",
    "    for x in df_sales_test.index:\n",
    "\n",
    "        df_sales_test.loc[x,:]=Y.loc[x][\"sales\"].values\n",
    "        df_promo_test.loc[x,:]=Y.loc[x][\"onpromotion\"].values          \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############ defining the exogenous variables for test ##############################\n",
    "    \n",
    "    df_exog_test=pd.merge(holiday_exog,oil_exog,how=\"inner\",left_index=True,right_index=True)\n",
    "\n",
    "    df_ind_test=pd.merge(df_promo_test,df_exog,how=\"inner\",left_index=True,right_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    ############ adding the lagged sales to exogenous, uses the already predicted values ##########\n",
    "    ######## the prediction for 15 day prediction is built from 1 day prediction at a time ########\n",
    "    \n",
    "    \n",
    "    temp_df_sales=df_sales.copy()\n",
    "    \n",
    "    \n",
    "    pred_test_array=[]\n",
    "    for i in range(split_length):\n",
    "        \n",
    "        ########## exogenous variable for one step ahead prediction #####################\n",
    "        df_ind_test_single=df_ind_test.iloc[i:i+1,:].copy()\n",
    "        \n",
    "        ########## adding the lagged sales to exogenous variable #################\n",
    "        \n",
    "        iterate=temp_df_sales.columns\n",
    "        for j in range(0,auto_reg_order):\n",
    "            for x in iterate:\n",
    "                df_ind_test_single[x+\" lag\" +str(j+1)]=temp_df_sales[x].shift(j)[-1]\n",
    "        \n",
    "        ######## one step ahead prediction #########################\n",
    "        \n",
    "        pred_test_array.append(reg_model.predict(df_ind_test_single.values.astype(np.float32))[-1])\n",
    "        \n",
    "        ######## adding the prediction to existing sales for lagged sales calculation ###########\n",
    "        \n",
    "        temp_df_sales.loc[temp_df_sales.index[-1]+timedelta(days=1)]=pred_test_array[-1]\n",
    "        \n",
    "        \n",
    "    ##### prediction before appling ARIMA or MA #####################\n",
    "    \n",
    "    pred_test=pd.DataFrame(pred_test_array,columns=df_sales.columns) \n",
    "    \n",
    "    ##### creating data frame for post ARIMA prediction #############\n",
    "    \n",
    "    pred_arima_test=pd.DataFrame(pred_test_array,columns=df_sales.columns)\n",
    "    \n",
    "    ##### residue from regression #######\n",
    "    \n",
    "    residue=pd.DataFrame(pred_train.values-df_sales.values[auto_reg_order:],columns=train_csv[\"family\"].unique(),index=df_ind.index)\n",
    "\n",
    "    ##### Applying MA to each column of residue separately ############\n",
    "    \n",
    "    for x in residue.columns:\n",
    "        print((\"Analysing store: {} and family: {}\").format(k,x))\n",
    "\n",
    "        arima_model=pmdarima.auto_arima(residue[x],trace=True,suppress_warnings=True,max_p=0,start_p=0)\n",
    "        arima_model_forecast=arima_model.predict(n_periods=15)\n",
    "\n",
    "        \n",
    "        ########## adding prediction to prection from regression #######\n",
    "        pred_arima_test[x]=pred_test[x].values-arima_model_forecast.values\n",
    "\n",
    "        \n",
    "    ########## replacing negative values with zeros in prediction dataframes ############\n",
    "    for z in pred_test.index:\n",
    "        for y in pred_test.columns:\n",
    "\n",
    "            if pred_test.loc[z,y]<=0:\n",
    "                pred_test.loc[z,y]=0\n",
    "                \n",
    "            if pred_arima_test.loc[z,y]<=0:\n",
    "                pred_arima_test.loc[z,y]=0\n",
    "    \n",
    "    \n",
    "    ############ LOG MSE for each store #################\n",
    "    error=math.sqrt(np.sum(np.square(np.log(pred_test.iloc[:,:].values.astype(np.float32)+1)-np.log(df_sales_test.iloc[:,:].values.astype(np.float32)+1)))/(15*33))\n",
    "    error_array.append([error,df_sales_test,pred_test,pred_arima_test])\n",
    "    clear_output(wait=True)\n",
    "    print((\"error for {}: {}\").format(k,error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a514767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## comparing sales test and predicted plots ################\n",
    "############################ for 5 stores ##############################\n",
    "for k in range(0,5):\n",
    "    plt.figure(figsize=(20,50))\n",
    "    plot_data=error_array[k]\n",
    "    for j in range(len(plot_data[1].columns)):\n",
    "        plt.subplot(11,3,j+1)\n",
    "        plt.plot([i for i in range(split_length)],plot_data[1][plot_data[1].columns[j]],label=\"sales\")\n",
    "        plt.plot([i for i in range(split_length)],plot_data[2][plot_data[1].columns[j]],label=\"pred_pre_arima\")\n",
    "        plt.plot([i for i in range(split_length)],plot_data[3][plot_data[1].columns[j]],label=\"pred_post_arima\")\n",
    "        plt.legend()\n",
    "        plt.title(plot_data[1].columns[j])\n",
    "    plt.suptitle((\"store number {}\").format(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b6ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sales_TS-Copy1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
